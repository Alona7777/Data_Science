{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "069c47d5-041b-4d65-ac02-2e66e302c41f",
      "metadata": {
        "id": "069c47d5-041b-4d65-ac02-2e66e302c41f",
        "outputId": "259b7dbe-0ce2-4763-cd6e-ea18270f2046",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\users\\tatya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
            "\n",
            "{' ': 1, 'о': 2, 'и': 3, 'н': 4, 'е': 5, 'і': 6, 'в': 7, 'а': 8, 'т': 9, 'д': 10, 'л': 11, 'р': 12, 'к': 13, 'я': 14, 'п': 15, 'з': 16, 'у': 17, 'с': 18, '\\n': 19, 'щ': 20, 'м': 21, 'й': 22, 'г': 23, 'ь': 24, 'ш': 25, 'б': 26, 'ю': 27, 'х': 28, 'ж': 29, 'ц': 30, 'ч': 31, 'є': 32}\n",
            "WARNING:tensorflow:From c:\\users\\tatya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " simple_rnn (SimpleRNN)      (None, 128)               20864     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 34)                4386      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25250 (98.63 KB)\n",
            "Trainable params: 25250 (98.63 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:From c:\\users\\tatya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "Epoch 1/100\n",
            "WARNING:tensorflow:From c:\\users\\tatya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
            "\n",
            "WARNING:tensorflow:From c:\\users\\tatya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
            "\n",
            "7/7 [==============================] - 3s 9ms/step - loss: 3.5089 - accuracy: 0.0539 \n",
            "Epoch 2/100\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 3.3230 - accuracy: 0.1716\n",
            "Epoch 3/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 3.1677 - accuracy: 0.2500\n",
            "Epoch 4/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 3.0137 - accuracy: 0.2157\n",
            "Epoch 5/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 2.8722 - accuracy: 0.2451\n",
            "Epoch 6/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 2.7467 - accuracy: 0.2402\n",
            "Epoch 7/100\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 2.6422 - accuracy: 0.2696\n",
            "Epoch 8/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 2.5418 - accuracy: 0.2745\n",
            "Epoch 9/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 2.4503 - accuracy: 0.3039\n",
            "Epoch 10/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 2.3612 - accuracy: 0.3284\n",
            "Epoch 11/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 2.2750 - accuracy: 0.3529\n",
            "Epoch 12/100\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 2.1924 - accuracy: 0.3824\n",
            "Epoch 13/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 2.1034 - accuracy: 0.4363\n",
            "Epoch 14/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 2.0231 - accuracy: 0.4510\n",
            "Epoch 15/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 1.9473 - accuracy: 0.4706\n",
            "Epoch 16/100\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 1.8702 - accuracy: 0.4755\n",
            "Epoch 17/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 1.7994 - accuracy: 0.4804\n",
            "Epoch 18/100\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 1.7246 - accuracy: 0.5098\n",
            "Epoch 19/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 1.6613 - accuracy: 0.5294\n",
            "Epoch 20/100\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 1.5940 - accuracy: 0.5637\n",
            "Epoch 21/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 1.5332 - accuracy: 0.6078\n",
            "Epoch 22/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 1.4780 - accuracy: 0.6373\n",
            "Epoch 23/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 1.4207 - accuracy: 0.6471\n",
            "Epoch 24/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 1.3642 - accuracy: 0.6520\n",
            "Epoch 25/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 1.3197 - accuracy: 0.6765\n",
            "Epoch 26/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 1.2723 - accuracy: 0.6912\n",
            "Epoch 27/100\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 1.2319 - accuracy: 0.6961\n",
            "Epoch 28/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 1.1918 - accuracy: 0.7010\n",
            "Epoch 29/100\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 1.1524 - accuracy: 0.7255\n",
            "Epoch 30/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 1.1174 - accuracy: 0.7402\n",
            "Epoch 31/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 1.0818 - accuracy: 0.7549\n",
            "Epoch 32/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 1.0495 - accuracy: 0.7549\n",
            "Epoch 33/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 1.0184 - accuracy: 0.7500\n",
            "Epoch 34/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.9916 - accuracy: 0.7745\n",
            "Epoch 35/100\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.9642 - accuracy: 0.7892\n",
            "Epoch 36/100\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.9373 - accuracy: 0.7941\n",
            "Epoch 37/100\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.9105 - accuracy: 0.7990\n",
            "Epoch 38/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.8870 - accuracy: 0.8284\n",
            "Epoch 39/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.8663 - accuracy: 0.8284\n",
            "Epoch 40/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.8393 - accuracy: 0.8431\n",
            "Epoch 41/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.8207 - accuracy: 0.8480\n",
            "Epoch 42/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.7977 - accuracy: 0.8480\n",
            "Epoch 43/100\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.7822 - accuracy: 0.8578\n",
            "Epoch 44/100\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.7614 - accuracy: 0.8775\n",
            "Epoch 45/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.7492 - accuracy: 0.8873\n",
            "Epoch 46/100\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.7325 - accuracy: 0.8922\n",
            "Epoch 47/100\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.7089 - accuracy: 0.9069\n",
            "Epoch 48/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.6963 - accuracy: 0.8725\n",
            "Epoch 49/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6790 - accuracy: 0.8676\n",
            "Epoch 50/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6642 - accuracy: 0.8824\n",
            "Epoch 51/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6504 - accuracy: 0.8725\n",
            "Epoch 52/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6388 - accuracy: 0.8873\n",
            "Epoch 53/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6240 - accuracy: 0.8971\n",
            "Epoch 54/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6075 - accuracy: 0.9069\n",
            "Epoch 55/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.6051 - accuracy: 0.9069\n",
            "Epoch 56/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.5866 - accuracy: 0.9167\n",
            "Epoch 57/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.5691 - accuracy: 0.9167\n",
            "Epoch 58/100\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.5592 - accuracy: 0.9118\n",
            "Epoch 59/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.5495 - accuracy: 0.9216\n",
            "Epoch 60/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.5382 - accuracy: 0.9216\n",
            "Epoch 61/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.5275 - accuracy: 0.9314\n",
            "Epoch 62/100\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.5181 - accuracy: 0.9216\n",
            "Epoch 63/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.5088 - accuracy: 0.9363\n",
            "Epoch 64/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.4996 - accuracy: 0.9265\n",
            "Epoch 65/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.4883 - accuracy: 0.9363\n",
            "Epoch 66/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.4760 - accuracy: 0.9510\n",
            "Epoch 67/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.4702 - accuracy: 0.9461\n",
            "Epoch 68/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.4679 - accuracy: 0.9559\n",
            "Epoch 69/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.4542 - accuracy: 0.9510\n",
            "Epoch 70/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.4464 - accuracy: 0.9314\n",
            "Epoch 71/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.4337 - accuracy: 0.9314\n",
            "Epoch 72/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.4300 - accuracy: 0.9412\n",
            "Epoch 73/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.4218 - accuracy: 0.9412\n",
            "Epoch 74/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.4155 - accuracy: 0.9412\n",
            "Epoch 75/100\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.4077 - accuracy: 0.9510\n",
            "Epoch 76/100\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.3966 - accuracy: 0.9608\n",
            "Epoch 77/100\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.3948 - accuracy: 0.9412\n",
            "Epoch 78/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.3888 - accuracy: 0.9461\n",
            "Epoch 79/100\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.3802 - accuracy: 0.9559\n",
            "Epoch 80/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.3799 - accuracy: 0.9461\n",
            "Epoch 81/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.3759 - accuracy: 0.9510\n",
            "Epoch 82/100\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.3633 - accuracy: 0.9510\n",
            "Epoch 83/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.3570 - accuracy: 0.9510\n",
            "Epoch 84/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.3546 - accuracy: 0.9412\n",
            "Epoch 85/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.3537 - accuracy: 0.9559\n",
            "Epoch 86/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.3388 - accuracy: 0.9510\n",
            "Epoch 87/100\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.3364 - accuracy: 0.9559\n",
            "Epoch 88/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.3288 - accuracy: 0.9461\n",
            "Epoch 89/100\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.3280 - accuracy: 0.9608\n",
            "Epoch 90/100\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.3211 - accuracy: 0.9608\n",
            "Epoch 91/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.3137 - accuracy: 0.9608\n",
            "Epoch 92/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.3095 - accuracy: 0.9608\n",
            "Epoch 93/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.3033 - accuracy: 0.9608\n",
            "Epoch 94/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.3009 - accuracy: 0.9706\n",
            "Epoch 95/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.2947 - accuracy: 0.9559\n",
            "Epoch 96/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.2977 - accuracy: 0.9461\n",
            "Epoch 97/100\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.2914 - accuracy: 0.9510\n",
            "Epoch 98/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.2848 - accuracy: 0.9608\n",
            "Epoch 99/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.2810 - accuracy: 0.9559\n",
            "Epoch 100/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.2750 - accuracy: 0.9608\n",
            "1/1 [==============================] - 0s 314ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 76ms/step\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 77ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "Якщ о рв зр огуниит нвіс тье доіснтью дтдсняоюил дк со\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import re\n",
        "\n",
        "from tensorflow.keras.layers import Dense, SimpleRNN, Input\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "text = \"\"\"\n",
        "• Ви - найкраще рішення для проблем, що виникли у понеділок.\n",
        "• Думайте позитивно і вірте в свою здатність досягати відмінних результатів.\n",
        "• Якщо ви змогли у понеділок піднятися з ліжка, це означає, що ви супергерой.\n",
        "\"\"\"\n",
        "\n",
        "# Обробка тексту\n",
        "text = re.sub(r'[^\\w\\s]', '', text)  # видаляє всі символи крім букв та пробілів\n",
        "\n",
        "# парсим текст, як послідовність символів\n",
        "num_characters = 34  # 33 букви + пробіл\n",
        "tokenizer = Tokenizer(num_words=num_characters, char_level=True)  # токенизуємо на рівні символів\n",
        "tokenizer.fit_on_texts([text])  # формуємо токени на основі частотності в нашому тексті\n",
        "print(tokenizer.word_index)\n",
        "\n",
        "inp_chars = 3\n",
        "data = tokenizer.texts_to_matrix(text)  # перетворюємо текст в масив\n",
        "n = data.shape[0] - inp_chars  # так як ми передбачаємо по трьох символах - четвертий\n",
        "\n",
        "X = np.array([data[i:i + inp_chars, :] for i in range(n)])\n",
        "Y = data[inp_chars:]  # передбачення наступного символа\n",
        "\n",
        "# архітектура моделі\n",
        "model = Sequential()\n",
        "model.add(Input((inp_chars, num_characters)))  # вказуємо два числа: довжину послідовності та розмір\n",
        "model.add(SimpleRNN(128, activation='tanh'))  # рекурентний шар на 128 нейронів\n",
        "model.add(Dense(num_characters, activation='softmax'))\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
        "\n",
        "# Тренування моделі\n",
        "history = model.fit(X, Y, batch_size=32, epochs=100)\n",
        "\n",
        "\n",
        "def buildPhrase(inp_str, str_len=50):\n",
        "    for i in range(str_len):\n",
        "        x = []\n",
        "        for j in range(i, i + inp_chars):\n",
        "            x.append(tokenizer.texts_to_matrix(inp_str[j]))  # перетворюємо символи в One-Hot-encoding\n",
        "\n",
        "        x = np.array(x)\n",
        "        inp = x.reshape(1, inp_chars, num_characters)\n",
        "\n",
        "        pred = model.predict(inp)  # передбачуємо  четвертого символа\n",
        "        d = tokenizer.index_word[pred.argmax(axis=1)[0]]  # отримуємо відповідь в символьному вигляді\n",
        "\n",
        "        inp_str += d  # дописуємо рядок\n",
        "\n",
        "    return inp_str\n",
        "\n",
        "\n",
        "res = buildPhrase(\"Якщ\")\n",
        "print(res)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e61f84a-28eb-4eb0-8683-2331ce02afd8",
      "metadata": {
        "id": "8e61f84a-28eb-4eb0-8683-2331ce02afd8"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
